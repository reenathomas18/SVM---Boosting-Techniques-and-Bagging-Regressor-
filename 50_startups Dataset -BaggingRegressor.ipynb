{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Task\n",
    "1. Bagging Regressor\n",
    "2. Decision Tree Regressor\n",
    "3. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset\n",
    "df = pd.read_csv('50_Startups.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()  # - Indicates that there are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() #Indicates that there are no outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "box_df = df.iloc[:,[0,1,2]]\n",
    "box_df.plot(kind='box', figsize= (7,5),subplots=True, layout=(1,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 : Bagging Classifier using Shuffling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entire training dataset will be considered for training each model however the data will be shuffled for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check and Handle categorical data\n",
    "#State is the only categorical data that needs to be handled. Rest are numerica data\n",
    "df.State.unique()\n",
    "dfU = pd.concat([pd.get_dummies(df.State), df.iloc[:,[0,1,2,4]]] , axis = 1)\n",
    "#pd.get_dummies(df.Pincode)\n",
    "dfU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dfU.iloc[:,:-1]\n",
    "label=dfU.iloc[:,[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging Classifier using Shuffling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Entire Training dataset will be considered for training each model, however the data will be shuffled for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                label,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DecisionTree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8999754768950823"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 50 records\n",
    "for i in range(1,51):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                label,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=i)\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    train_s=model.score(X_train,y_train)\n",
    "    test_s=model.score(X_test,y_test)\n",
    "    \n",
    "    if test_s > train_s:\n",
    "        print(\"{}{}{}\".format(test_s,train_s,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Bagging with Shuffling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse',\n",
       "                                                      max_depth=None,\n",
       "                                                      max_features=None,\n",
       "                                                      max_leaf_nodes=None,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1,\n",
       "                                                      min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      presort=False,\n",
       "                                                      random_state=None,\n",
       "                                                      splitter='best'),\n",
       "                 bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                 max_samples=1.0, n_estimators=11, n_jobs=None, oob_score=False,\n",
       "                 random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "algorithm = DecisionTreeRegressor()\n",
    "\n",
    "model = BaggingRegressor(n_estimators=11,\n",
    "                         base_estimator=algorithm)\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9873195293291875\n",
      "0.8904641286401438\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def determine_no_of_estimators(features,label):\n",
    "    max_val = 0\n",
    "    no_of_estimators = 0\n",
    "    for i in range(1,51):\n",
    "        X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                    label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=10)\n",
    "        algorithm = DecisionTreeRegressor()\n",
    "        model = BaggingRegressor(n_estimators=i,\n",
    "                             base_estimator=algorithm)\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        train_s=model.score(X_train,y_train)\n",
    "        test_s=model.score(X_test,y_test)\n",
    "\n",
    "        if test_s > train_s:\n",
    "            if test_s > max_val:\n",
    "                max_val = test_s\n",
    "                no_of_estimators = i\n",
    "            \n",
    "            print(\"Test score =  {} Train score = {} No of estimators = {}\".format(test_s,train_s,i))\n",
    "    return no_of_estimators\n",
    "no_of_estimators = determine_no_of_estimators(features,label)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Bagging with Sampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Without Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we are dealing with regression models sample size = total no of data points in training data / no of learners\n",
    "sampleSize = len(X_train)/no_of_estimators\n",
    "sampleSize  = int(round(sampleSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                label,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=10)\n",
    "algorithm = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709929287144603\n",
      "0.9729004145525064\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score = 0.9693416680610817 Train score = 0.9459490390786907 RS =2\n",
      "Test score = 0.9654848886426531 Train score = 0.9265924279944222 RS =3\n",
      "Test score = 0.9468201944720942 Train score = 0.9419491236616544 RS =13\n",
      "Test score = 0.9473618225781384 Train score = 0.9038223104483133 RS =14\n",
      "Test score = 0.9553437615558471 Train score = 0.9517267196821368 RS =20\n",
      "Test score = 0.9616959843931283 Train score = 0.931877345938491 RS =26\n",
      "Test score = 0.9511747961161905 Train score = 0.9427144085600055 RS =29\n",
      "Test score = 0.9336283056066856 Train score = 0.9262370311490108 RS =33\n",
      "Test score = 0.9209536837402529 Train score = 0.9196836591709625 RS =46\n",
      "Random state corresponding to max test score 0.9693416680610817 is 2 \n"
     ]
    }
   ],
   "source": [
    "def determine_RS(features,label):\n",
    "    max_val = 0\n",
    "    rs = 0\n",
    "    for i in range(1,51):\n",
    "        X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                    label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=i)\n",
    "        algorithm = DecisionTreeRegressor()\n",
    "        modelSampleTechnique2 = BaggingRegressor(n_estimators=11, #no of learners\n",
    "                                             base_estimator=algorithm, #algorithm\n",
    "                                             max_samples=sampleSize, #No of data pts per model\n",
    "                                             bootstrap=False,#Sample Without Replacement\n",
    "                                             random_state=76) \n",
    "        modelSampleTechnique2.fit(X_train,y_train)\n",
    "\n",
    "        train_s=modelSampleTechnique2.score(X_train,y_train)\n",
    "        test_s=modelSampleTechnique2.score(X_test,y_test)\n",
    "\n",
    "        if test_s > train_s:\n",
    "            print(\"Test score = {} Train score = {} RS ={}\".format(test_s,train_s,i))\n",
    "            if test_s > max_val:\n",
    "                max_val = test_s\n",
    "                rs = i\n",
    "    return max_val , rs\n",
    "max_ts, max_rs = determine_RS(features, label)\n",
    "print (\"Random state corresponding to max test score {} is {} \" .format(max_ts, max_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. With Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score = 0.8919379952440745 Train score = 0.8860803346678642 RS =2\n",
      "Test score = 0.941050272024652 Train score = 0.8925931978467356 RS =3\n",
      "Test score = 0.9157127265797238 Train score = 0.9067875184640424 RS =4\n",
      "Test score = 0.9432224867101977 Train score = 0.9414596398761991 RS =22\n",
      "Test score = 0.9251395738708864 Train score = 0.900482837062811 RS =30\n",
      "Test score = 0.8634144021387982 Train score = 0.8610630402091708 RS =33\n",
      "Test score = 0.8879468643645297 Train score = 0.8839699244494306 RS =38\n",
      "Test score = 0.9353603545240813 Train score = 0.9265152100901143 RS =45\n",
      "Test score = 0.920202983796646 Train score = 0.9044764278012868 RS =48\n",
      "Random state corresponding to max test score 0.9432224867101977 is 22 \n"
     ]
    }
   ],
   "source": [
    "def determine_RS(features,label):\n",
    "    max_val = 0\n",
    "    rs = 0\n",
    "    for i in range(1,51):\n",
    "        X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                    label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=i)\n",
    "        algorithm = DecisionTreeRegressor()\n",
    "        modelSampleTechnique2 = BaggingRegressor(n_estimators=11, #no of learners\n",
    "                                             base_estimator=algorithm, #algorithm\n",
    "                                             max_samples=sampleSize, #No of data pts per model\n",
    "                                             bootstrap=True,#Sample With Replacement\n",
    "                                             random_state=76) \n",
    "        modelSampleTechnique2.fit(X_train,y_train)\n",
    "\n",
    "        train_s=modelSampleTechnique2.score(X_train,y_train)\n",
    "        test_s=modelSampleTechnique2.score(X_test,y_test)\n",
    "\n",
    "        if test_s > train_s:\n",
    "            print(\"Test score = {} Train score = {} RS ={}\".format(test_s,train_s,i))\n",
    "            if test_s > max_val:\n",
    "                max_val = test_s\n",
    "                rs = i\n",
    "    return max_val , rs\n",
    "max_ts, max_rs = determine_RS(features, label)\n",
    "print (\"Random state corresponding to max test score {} is {} \" .format(max_ts, max_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "for i in range(1,51):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                label,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=i)\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    train_s=model.score(X_train,y_train)\n",
    "    test_s=model.score(X_test,y_test)\n",
    "    \n",
    "    if test_s > train_s:\n",
    "        print(\"Test score {} Train Score {} RS {}\".format(test_s,train_s,i))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876621559069144"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8975224839382848"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion : Its an overfitted model, so lets apply Bagging\n",
    "\n",
    "#Works only on Shuffling Bagging and not Sampling Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Bagging Regressor using Shuffling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entire Training dataset will be considered for training each model, however the data will be shuffled for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                      criterion='mse',\n",
       "                                                      max_depth=None,\n",
       "                                                      max_features='auto',\n",
       "                                                      max_leaf_nodes=None,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1,\n",
       "                                                      min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      n_estimators='warn',\n",
       "                                                      n_jobs=None,\n",
       "                                                      oob_score=False,\n",
       "                                                      random_state=None,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False),\n",
       "                 bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                 max_samples=1.0, n_estimators=11, n_jobs=None, oob_score=False,\n",
       "                 random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "algorithm = RandomForestRegressor()\n",
    "\n",
    "model = BaggingRegressor(n_estimators=11,\n",
    "                         base_estimator=algorithm)\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9708067240675895"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904188969756195"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score 0.964000600066746 Train Score 0.9623136207420012 RS 10\n",
      "Random state corresponding to max test score 0.9432224867101977 is 22 \n"
     ]
    }
   ],
   "source": [
    "def determine_RS(features,label):\n",
    "    max_val = 0\n",
    "    rs = 0\n",
    "    for i in range(1,51):\n",
    "        X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                    label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=i)\n",
    "        algorithm = RandomForestRegressor()\n",
    "        model = BaggingRegressor(n_estimators=11,\n",
    "                             base_estimator=algorithm)\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        train_s=model.score(X_train,y_train)\n",
    "        test_s=model.score(X_test,y_test)\n",
    "\n",
    "        if test_s > train_s:\n",
    "            print(\"Test Score {} Train Score {} RS {}\".format(test_s,train_s,i))\n",
    "            if test_s > max_val:\n",
    "                max_val = test_s\n",
    "                rs = i\n",
    "    return max_ts, max_rs, model\n",
    "\n",
    "max_ts, max_rs , model = determine_RS(features,label)\n",
    "print (\"Random state corresponding to max test score %r is %r \" %(max_ts, max_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pre-deployment Test\n",
    "# App Example\n",
    "\n",
    "rdSpend = float(input(\"Enter R&D Expenditure: \"))\n",
    "adminSpend = float(input(\"Enter Administration Expenditure: \"))\n",
    "markgSpend = float(input(\"Enter Marketing Expenditure: \"))\n",
    "\n",
    "#Format of Input must be same as that used in training\n",
    "#profit = model.predict(np.array([[rdSpend,adminSpend,markgSpend]]))\n",
    "\n",
    "#print(\"Estimated Profit for the company is: \", profit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
